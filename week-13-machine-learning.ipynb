{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aea4d09-f1d5-41fd-ad9b-575d3ea6d115",
   "metadata": {},
   "source": [
    "# Week-13: Classification Task in Python\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Welcome back!\n",
    "* Today, we will go over a classification example using `skicit-learn` package in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12028f21-bd8b-464a-899f-0acfe3e41a8a",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* HW8 Q1: The location of files are misplaced. Suppose that `python_proj` is your working directory, <br> `HW8_main.py` should be put right under `python_proj`, while `HW8Fun.py` should be put under `self_py_fun` folder.\n",
    "* Interpretation of parameters of the linear model is not correct:\n",
    "* <img src=\"figures/HW8_linear_model_output.png\" alt=\"drawing\" width=\"500\"/>\n",
    "* For continuous covariate, i.e., CTQ total score, you should write:\n",
    "    * One score increase in CTQ total score, on average, corresponds to a 0.042 score increase in PCL5 score at intake, adjusting for other covariates (p=0.025, 95% CI: [0.003, 0.081]).\n",
    "* For categorical covariate, i.e., military rank, you should have reference group:\n",
    "    * Patients who are officers, on average, had lower PCL5 score at intake by 3.06 than patients who are enlisted, adjusting for other covariates (p=0.022, 95% CI: [0.44, 5.67]). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa492eb-75f3-4984-89d1-3f8dbc75c1e1",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* `Scikit-learn`, known as `sklearn`, is an open-source, robust library for machine learning in Python.\n",
    "* It is created to streamline the process of implementing machine learning and statistical models in Python.\n",
    "* The package comes with standard machine learning datasets, and you can import it without downloading them from an external website or database.\n",
    "* Since we will go over a classification example, we will be using the [`wine dataset`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine) (Click it for more information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "223e4dda-3948-42c5-a85f-cf78f2313181",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DecsionTreeClassifier' from 'sklearn.tree' (/Users/lipingchen/Documents/GitHub/BIOS-584/.venv/lib/python3.11/site-packages/sklearn/tree/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msvm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SVC\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DecsionTreeClassifier\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'DecsionTreeClassifier' from 'sklearn.tree' (/Users/lipingchen/Documents/GitHub/BIOS-584/.venv/lib/python3.11/site-packages/sklearn/tree/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecsionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7784c3c-f727-4d4f-9059-d60534adb560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "wine_data = load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa967e98-158c-4c66-9884-9f1dae36d3f0",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* Executing the above code returns a dictionary-like object (we just learned!) that contains data and metadata.\n",
    "    * **Metadata**: This is a terminology for data dictionary, i.e., a description of the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7937920-8ae3-4389-9b6f-92b435c5da53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the data to a Pandas dataframe\n",
    "wine_df = pd.DataFrame(wine_data.data, columns=wine_data.feature_names)\n",
    "\n",
    "# Add the target label (add a new column)\n",
    "wine_df['target']= wine_data.target\n",
    "\n",
    "# Preview\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c4669-c36c-4440-abda-1f44904503c8",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Before conducting any data analysis, always check the quality of the dataset with exploratory data analysis.\n",
    "* You can call `.info()` method to print out a summary of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d92a6cb-135f-4c9e-b6b1-f1756f95a7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       178 non-null    float64\n",
      " 1   malic_acid                    178 non-null    float64\n",
      " 2   ash                           178 non-null    float64\n",
      " 3   alcalinity_of_ash             178 non-null    float64\n",
      " 4   magnesium                     178 non-null    float64\n",
      " 5   total_phenols                 178 non-null    float64\n",
      " 6   flavanoids                    178 non-null    float64\n",
      " 7   nonflavanoid_phenols          178 non-null    float64\n",
      " 8   proanthocyanins               178 non-null    float64\n",
      " 9   color_intensity               178 non-null    float64\n",
      " 10  hue                           178 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
      " 12  proline                       178 non-null    float64\n",
      " 13  target                        178 non-null    int64  \n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "wine_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b0aa481-ea19-4070-9833-2764d7bad8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "      <td>0.938202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "      <td>0.775035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
       "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
       "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
       "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
       "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
       "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
       "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
       "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
       "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
       "\n",
       "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "count     178.000000  178.000000            178.000000       178.000000   \n",
       "mean        2.295112    2.029270              0.361854         1.590899   \n",
       "std         0.625851    0.998859              0.124453         0.572359   \n",
       "min         0.980000    0.340000              0.130000         0.410000   \n",
       "25%         1.742500    1.205000              0.270000         1.250000   \n",
       "50%         2.355000    2.135000              0.340000         1.555000   \n",
       "75%         2.800000    2.875000              0.437500         1.950000   \n",
       "max         3.880000    5.080000              0.660000         3.580000   \n",
       "\n",
       "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \\\n",
       "count       178.000000  178.000000                    178.000000   178.000000   \n",
       "mean          5.058090    0.957449                      2.611685   746.893258   \n",
       "std           2.318286    0.228572                      0.709990   314.907474   \n",
       "min           1.280000    0.480000                      1.270000   278.000000   \n",
       "25%           3.220000    0.782500                      1.937500   500.500000   \n",
       "50%           4.690000    0.965000                      2.780000   673.500000   \n",
       "75%           6.200000    1.120000                      3.170000   985.000000   \n",
       "max          13.000000    1.710000                      4.000000  1680.000000   \n",
       "\n",
       "           target  \n",
       "count  178.000000  \n",
       "mean     0.938202  \n",
       "std      0.775035  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      1.000000  \n",
       "75%      2.000000  \n",
       "max      2.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666a1c0f-62e8-41fb-b99f-c0805b20846c",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* There are 178 data samples with 14 columns including the target column (output that we would like to predict).\n",
    "* Luckily, no missing values are in our dataset from `Non-Null Count`.\n",
    "* All features are `float64` except for target column.\n",
    "* The dataset consumes 19.6 KB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff288d89-e926-4e28-a68f-af964852220a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (2509379315.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mwine_df['target'].value_counts[(normalize = True)*100], axis = 1)\u001b[39m\n                                    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "pd.concat(wine_df['target'].value_counts(),\n",
    "          wine_df['target'].value_counts(normalize = True)*100, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236003c9-dd43-46d1-a97d-73fae18cb918",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* Since `target` is a categorical variable, we check the frequency and proportion using `.value_counts()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c004e86-3ebf-4f45-8726-e1e632fedc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a0d8b1b-d433-4312-acfc-50efc4e66f65",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Preprocessing is important prior to applying machine learning algorithms.\n",
    "    * Check missing values, outliers, duplicates, errors, and data types.\n",
    "    * Avoid \"Garbage in, garbage out.\"\n",
    "* Machine learning models typically require numerical inputs.\n",
    "* Another practice is to standardize the input (via Z-transform) to make predictors more comparable. \n",
    "    * We do not want predictor A has a magnitude of 10000, while predictor B has a magnitude of 0.1.\n",
    "    * We can achieve the goal using `StandardScaler()` class.\n",
    "    * Each value goes through the following transformation columnwise, i.e., $x = (x - x_{mean})/x_{sd}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30d2b253-5ee5-4594-9707-5004ced1dab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "# Remember to import standardscaler (code should be written in the beginning of the Jupyter notebook).\n",
    "# Split data into features (input) and label (output)\n",
    "print(wine_data.feature_names)\n",
    "\n",
    "# Always make a copy to avoid making changes to the raw data (when you have sufficient amount of memory).\n",
    "x_mat = wine_df[wine_data.feature_names].copy()\n",
    "y_mat = wine_df['target'].copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9da298-4547-409f-9ff5-f67e1329648c",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "<img src=\"figures/sklearn_flowchart_1.png\" alt=\"drawing\" width=\"900\"/>\n",
    "    \n",
    "* In this flowchart, no output data are involved. We use `.transform()` in the last step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7eacfaa-6c63-40b9-bd42-d12ed548946e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(178, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.51861254, -0.5622498 ,  0.23205254, -1.16959318,  1.91390522,\n",
       "        0.80899739,  1.03481896, -0.65956311,  1.22488398,  0.25171685,\n",
       "        0.36217728,  1.84791957,  1.01300893])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate scaler and fit on features\n",
    "scaler_obj = StandardScaler()\n",
    "scaler_obj = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "# apply changes to training data\n",
    "# and update parameters (in this case, no model parameters are available, so this is optional)\n",
    "scaler_obj.fit(x_mat)\n",
    "\n",
    "# apply changes to any data and assign it with another variable\n",
    "x_scaled_mat = scaler_obj.transform(x_mat)\n",
    "\n",
    "# view the transformed output\n",
    "print(type(x_scaled_mat))\n",
    "print(x_scaled_mat.shape)\n",
    "x_scaled_mat[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a459bb-862e-4c49-84c2-47aa0aff4a8e",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* As we previously mentioned, we need to have training and testing set when we perform classification tasks.\n",
    "* If rows of input data are independent of each other, we can randomly select training and testing set.\n",
    "* Sklearn package has a built-in function called `train_test_split()`.\n",
    "* We usually set 70% data to train and 30% to test. The exact ratio vary depending on the volume of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20bc0777-625c-4780-adab-b7f81478d0ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input should have at least 1 dimension i.e. satisfy `len(x.shape) > 0`, got scalar `array(<bound method NDFrame.copy of 0      0\n1      0\n2      0\n3      0\n4      0\n      ..\n173    2\n174    2\n175    2\n176    2\n177    2\nName: target, Length: 178, dtype: int64>, dtype=object)` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# remember to import train_test_split in the beginning\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m x_train_scaled, x_test_scaled, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_scaled_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Check the splits are correct\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(x_train_scaled.shape[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/BIOS-584/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/BIOS-584/.venv/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2916\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_arrays == \u001b[32m0\u001b[39m:\n\u001b[32m   2914\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAt least one array required as input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2916\u001b[39m arrays = \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2918\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m   2919\u001b[39m n_train, n_test = _validate_shuffle_split(\n\u001b[32m   2920\u001b[39m     n_samples, test_size, train_size, default_test_size=\u001b[32m0.25\u001b[39m\n\u001b[32m   2921\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/BIOS-584/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:530\u001b[39m, in \u001b[36mindexable\u001b[39m\u001b[34m(*iterables)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[32m    501\u001b[39m \n\u001b[32m    502\u001b[39m \u001b[33;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    526\u001b[39m \u001b[33;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    529\u001b[39m result = [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/BIOS-584/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:471\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_consistent_length\u001b[39m(*arrays):\n\u001b[32m    455\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[32m    456\u001b[39m \n\u001b[32m    457\u001b[39m \u001b[33;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m \u001b[33;03m    >>> check_consistent_length(a, b)\u001b[39;00m\n\u001b[32m    470\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     lengths = \u001b[43m[\u001b[49m\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\n\u001b[32m    472\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) > \u001b[32m1\u001b[39m:\n\u001b[32m    473\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    474\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m             % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    476\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/BIOS-584/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:471\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_consistent_length\u001b[39m(*arrays):\n\u001b[32m    455\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[32m    456\u001b[39m \n\u001b[32m    457\u001b[39m \u001b[33;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m \u001b[33;03m    >>> check_consistent_length(a, b)\u001b[39;00m\n\u001b[32m    470\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m     lengths = [\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    472\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) > \u001b[32m1\u001b[39m:\n\u001b[32m    473\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    474\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m             % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    476\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/BIOS-584/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:399\u001b[39m, in \u001b[36m_num_samples\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m x.shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x.shape) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    400\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mInput should have at least 1 dimension i.e. satisfy \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    401\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`len(x.shape) > 0`, got scalar `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    402\u001b[39m         )\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Check that shape is returning an integer or default to len\u001b[39;00m\n\u001b[32m    404\u001b[39m     \u001b[38;5;66;03m# Dask dataframes may not return numeric shape[0] value\u001b[39;00m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x.shape[\u001b[32m0\u001b[39m], numbers.Integral):\n",
      "\u001b[31mTypeError\u001b[39m: Input should have at least 1 dimension i.e. satisfy `len(x.shape) > 0`, got scalar `array(<bound method NDFrame.copy of 0      0\n1      0\n2      0\n3      0\n4      0\n      ..\n173    2\n174    2\n175    2\n176    2\n177    2\nName: target, Length: 178, dtype: int64>, dtype=object)` instead."
     ]
    }
   ],
   "source": [
    "# remember to import train_test_split in the beginning\n",
    "x_train_scaled, x_test_scaled, y_train, y_test = train_test_split(x_scaled_mat, y_mat, train_size=0.7, random_state = 100)\n",
    "\n",
    "# Check the splits are correct\n",
    "print(x_train_scaled.shape[0])\n",
    "print(x_test_scaled.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c7783-41c7-43aa-bdbb-e6284aea7f24",
   "metadata": {},
   "source": [
    "### Model building\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Sklearn has numerous built-in classification methods. We will demonstrate a couple of methods including\n",
    "    * logistic regression\n",
    "    * support vector machine\n",
    "    * decision tree classifier\n",
    "    \n",
    "* <img src=\"figures/sklearn_flowchart_2.png\" alt=\"drawing\" width=\"900\"/>\n",
    "\n",
    "    * In this flowchart, both input and output (in the training set) are involved, so `.predict()` is used finally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb40ecea-5e32-4d35-85b9-14a2db776698",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m logistic_obj = LogisticRegression()\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Training the models \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m logistic_obj.fit(\u001b[43mx_train_scaled\u001b[49m, y_train)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Making predictions with each model\u001b[39;00m\n\u001b[32m     11\u001b[39m log_reg_preds = logistic_obj.predict(x_test_scaled)\n",
      "\u001b[31mNameError\u001b[39m: name 'x_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Iniatiating the models \n",
    "# Sometimes, you need to modify the parameters inside each of the function.\n",
    "# If not, the model will use its default values.\n",
    "# write one model and the rest two are completed by students\n",
    "logistic_obj = LogisticRegression()\n",
    "\n",
    "# Training the models \n",
    "logistic_obj.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Making predictions with each model\n",
    "log_reg_preds = logistic_obj.predict(x_test_scaled)\n",
    "print(log_reg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7134d7-885e-4352-b536-4b5340e0fc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write one model and the rest two are completed by students\n",
    "logistic_obj = LogisticRegression()\n",
    "\n",
    "# Training the models \n",
    "logistic_obj.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Making predictions with each model\n",
    "log_reg_preds = logistic_obj.predict(x_test_scaled)\n",
    "print(log_reg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc6d21d-9290-45a1-937e-460b36048966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can view the probability vector per measure per method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed927f6-e723-4ed2-a972-0ba05add1976",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* In our case, we will use `classification_report()` to build a text report showing main classification metrics such as `precision`, `recall`, `f1_score`, `accuracy`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b856b675-5f55-48b6-8bcf-8ffec1ab6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report (put it in the beginning)\n",
    "# Store model predictions in a dictionary\n",
    "# this makes it easier to iterate through each model\n",
    "# and print the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9de809-15bc-440f-b76d-bfdb164fbdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83993ee6-7db1-441a-b46a-d21a986e3168",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "The reported averages include \n",
    "\n",
    "* (sample) average (only for multilabel classification). \n",
    "* macro average (averaging the unweighted mean per label), \n",
    "* weighted average (averaging the support-weighted mean per label).\n",
    "\n",
    "Which method performs the best?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
